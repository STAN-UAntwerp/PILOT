{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble._gb import BaseGradientBoosting\n",
    "from sklearn.ensemble._gb_losses import LeastSquaresError\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "if pathlib.Path().parent.resolve().absolute().as_posix() not in sys.path:\n",
    "    sys.path.append(pathlib.Path().parent.resolve().absolute().as_posix())\n",
    "\n",
    "from pilot import Pilot\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete = pd.read_excel(\"https://archive.ics.uci.edu/ml/machine-learning-databases/concrete/compressive/Concrete_Data.xls\")\n",
    "concrete_X_train, concrete_X_test, concrete_y_train, concrete_y_test = train_test_split(concrete.iloc[:, :-1], concrete.iloc[:, -1], test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientBoostedPilot(GradientBoostingRegressor):\n",
    "    def __init__(\n",
    "        self, \n",
    "        *,\n",
    "        max_depth: int = 12, \n",
    "        split_criterion: str = 'BIC',\n",
    "        min_sample_split: int = 10, \n",
    "        min_sample_leaf: int = 5, \n",
    "        step_size: int = 1,\n",
    "        categorical_idx: np.ndarray = np.array([-1]),   \n",
    "        loss=\"squared_error\",\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=100,\n",
    "        subsample=1.0,\n",
    "        criterion=\"friedman_mse\",\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        min_weight_fraction_leaf=0.0,\n",
    "        min_impurity_decrease=0.0,\n",
    "        init=None,\n",
    "        random_state=None,\n",
    "        max_features=None,\n",
    "        alpha=0.9,\n",
    "        verbose=0,\n",
    "        max_leaf_nodes=None,\n",
    "        warm_start=False,\n",
    "        validation_fraction=0.1,\n",
    "        n_iter_no_change=None,\n",
    "        tol=1e-4,\n",
    "        ccp_alpha=0.0,\n",
    "        ):\n",
    "        super().__init__(\n",
    "            loss=loss,\n",
    "            learning_rate=learning_rate,\n",
    "            n_estimators=n_estimators,\n",
    "            criterion=criterion,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "            max_depth=max_depth,\n",
    "            init=init,\n",
    "            subsample=subsample,\n",
    "            max_features=max_features,\n",
    "            min_impurity_decrease=min_impurity_decrease,\n",
    "            random_state=random_state,\n",
    "            alpha=alpha,\n",
    "            verbose=verbose,\n",
    "            max_leaf_nodes=max_leaf_nodes,\n",
    "            warm_start=warm_start,\n",
    "            validation_fraction=validation_fraction,\n",
    "            n_iter_no_change=n_iter_no_change,\n",
    "            tol=tol,\n",
    "            ccp_alpha=ccp_alpha\n",
    "        )\n",
    "        self.max_depth = max_depth\n",
    "        self.split_criterion = split_criterion\n",
    "        self.min_sample_split = min_sample_split\n",
    "        self.min_sample_leaf = min_sample_leaf\n",
    "        self.step_size = step_size\n",
    "        self.categorical_idx = categorical_idx\n",
    "        \n",
    "    def _fit_stage(\n",
    "        self,\n",
    "        i,\n",
    "        X,\n",
    "        y,\n",
    "        raw_predictions,\n",
    "        sample_weight,\n",
    "        sample_mask,\n",
    "        random_state,\n",
    "        X_csc=None,\n",
    "        X_csr=None\n",
    "        ):\n",
    "        \n",
    "\n",
    "        assert sample_mask.dtype == bool\n",
    "        loss = self._loss\n",
    "        original_y = y\n",
    "\n",
    "        # Need to pass a copy of raw_predictions to negative_gradient()\n",
    "        # because raw_predictions is partially updated at the end of the loop\n",
    "        # in update_terminal_regions(), and gradients need to be evaluated at\n",
    "        # iteration i - 1.\n",
    "        raw_predictions_copy = raw_predictions.copy()\n",
    "\n",
    "        for k in range(loss.K):\n",
    "            if loss.is_multi_class:\n",
    "                y = np.array(original_y == k, dtype=np.float64)\n",
    "\n",
    "            residual = loss.negative_gradient(\n",
    "                y, raw_predictions_copy, k=k, sample_weight=sample_weight\n",
    "            )\n",
    "\n",
    "            # induce regression tree on residuals\n",
    "            tree = Pilot.PILOT(\n",
    "                max_depth=self.max_depth,\n",
    "                split_criterion=self.split_criterion,\n",
    "                min_sample_split=self.min_sample_split,\n",
    "                min_sample_leaf=self.min_sample_leaf,\n",
    "                step_size=self.step_size,\n",
    "            )\n",
    "\n",
    "            X = X_csr if X_csr is not None else X\n",
    "            tree.fit(X, residual, categorical=self.categorical_idx)\n",
    "\n",
    "            # update tree leaves\n",
    "            loss.update_terminal_regions(\n",
    "                tree,\n",
    "                X,\n",
    "                y,\n",
    "                residual,\n",
    "                raw_predictions,\n",
    "                sample_weight,\n",
    "                sample_mask,\n",
    "                learning_rate=self.learning_rate,\n",
    "                k=k,\n",
    "            )\n",
    "\n",
    "            # add tree to ensemble\n",
    "            self.estimators_[i, k] = tree\n",
    "\n",
    "        return raw_predictions\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = np.array(X)\n",
    "        base_prediction = self._raw_predict_init(X)\n",
    "        tree_predictions = np.array([self.learning_rate * e.predict(X) for e in self.estimators_.flatten()])\n",
    "        return  base_prediction + tree_predictions.sum(axis=0).reshape(-1, 1)\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.93692538225475"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pilot_gb = GradientBoostedPilot(n_estimators=100, categorical_idx=np.array([-1]))\n",
    "pilot_gb.fit(concrete_X_train, concrete_y_train)\n",
    "y_pred = pilot_gb.predict(X=concrete_X_test)\n",
    "mean_squared_error(concrete_y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.696433666134"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbd = GradientBoostingRegressor()\n",
    "gbd.fit(concrete_X_train, concrete_y_train)\n",
    "\n",
    "y_pred = gbd.predict(X=concrete_X_test)\n",
    "mean_squared_error(concrete_y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pilot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fd3ad90d96ad65fa4600695779b053fe5094545612b705888114d7bf126e60b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
